{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Researches using MVImgNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name(link) | Core idea | Tasks | Points |\n",
    "| ---- | ---- | ---- | ---- |\n",
    "| [Anydoor: Zero-shot object-level image customization](https://arxiv.org/abs/2307.09481) | **AnyDoor** | diffusion-based image generator | 1. use DINO v2 to train discriminator |\n",
    "| [Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets](https://arxiv.org/abs/2311.15127) | Video diffusion: train on text-to-video | fine-tuning |  |\n",
    "| [Autodecoding latent 3d diffusion models](https://arxiv.org/abs/2307.05445) | 3D diffusion from 2D images based on Autoencoder -->volumetric autodecoding | as real-world test dataset |  |\n",
    "| [Dmv3d: Denoising multi-view diffusion using 3d large reconstruction model](https://arxiv.org/abs/2311.09217) | 3D diffusion based on transformer and NeRF | training dataset |  |\n",
    "| [Invariant training 2d-3d joint hard samples for few-shot point cloud recognition](https://openaccess.thecvf.com/content/ICCV2023/html/Yi_Invariant_Training_2D-3D_Joint_Hard_Samples_for_Few-Shot_Point_Cloud_ICCV_2023_paper.html) | 2D-3D point cloud recognition |  |  |\n",
    "| [Deep learning based computer vision under the prism of 3D point clouds: a systematic review](https://link.springer.com/article/10.1007/s00371-023-03237-7) | 3D point cloud | 3D point cloud benchmark datasets |  |\n",
    "| [Evaluation of 3D Reconstruction for Cultural Heritage Applications](https://openaccess.thecvf.com/content/ICCV2023W/e-Heritage/html/Llull_Evaluation_of_3D_Reconstruction_for_Cultural_Heritage_Applications_ICCVW_2023_paper.html) | 3D reconstruction | 3D reconstruction benchmark |  |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
